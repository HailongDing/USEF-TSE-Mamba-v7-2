# âœ… USEF-TSE-Mamba V7 - Ready to Train!

## Configuration Verified

All parameters have been checked and are **consistent**:

### Model Configuration âœ…
- **Model**: `USEF_TSE_Mamba_v7_Enhanced`
- **Memory**: 14.2 GB (60% of 24GB)
- **Architecture**: Bottleneck-only attention (efficient)
- **Regularization**: Dropout 0.2, EMA, weight decay 0.05

### Dataset Configuration âœ…
- **Train**: 30,000 samples (50 hours)
- **Validation**: 2,000 samples (3.3 hours)
- **Test**: 1,000 samples (1.7 hours)
- **Audio**: 6s mixtures, 4s references @ 8kHz
- **Augmentation**: MixUp, SpecAugment, speed perturbation

### Training Configuration âœ…
- **Batch size**: 2 with grad accumulation 4 (effective 8)
- **Workers**: 16 parallel data loaders
- **Validation**: Quick (500) every 5 epochs, full every 10
- **Mixed precision**: Enabled for efficiency
- **Expected time**: ~47 hours for 150 epochs

### File Organization âœ…
- **Active files**: 12 essential Python files
- **Configs**: 2 optimized configurations
- **Legacy files**: Safely archived in `_archived_v7_cleanup/`

## Training Commands

### Step 1: Generate Optimized Dataset
```bash
./regenerate_dataset_optimized.sh

# Choose option 1 (parallel) for 45-60 min generation
# This creates 30K/2K/1K split with extended audio
```

### Step 2: Start Training
```bash
python src/train_v7.py --config configs/config_v7_optimized.yaml

# Training will:
# - Use cached data loader (LRU 1024 files)
# - Apply augmentation (if enabled)
# - Save checkpoints every 5 epochs
# - Log to TensorBoard
```

### Step 3: Monitor Progress
```bash
# In another terminal:
tensorboard --logdir outputs/usef_tse_v7_optimized

# Open browser to http://localhost:6006
```

### Step 4: Run Inference
```bash
# Test on audio files:
python src/inference_v7.py \
    --checkpoint checkpoints/usef_tse_v7_optimized/best_model.pt \
    --config configs/config_v7_optimized.yaml \
    --mixture test_audio/mix.wav \
    --reference test_audio/ref.wav \
    --output test_audio/extracted_v7.wav

# Process entire test set with metrics:
python src/inference_v7.py \
    --checkpoint checkpoints/usef_tse_v7_optimized/best_model.pt \
    --config configs/config_v7_optimized.yaml \
    --dataset /data/tse_audio_dataset_v7_optimized \
    --split test \
    --output_dir test_output \
    --compute_metrics \
    --metrics_file test_results.csv
```

## Expected Performance

| Metric | Target | Notes |
|--------|--------|-------|
| **SI-SDRi** | 11-13 dB | vs 8.75 dB in v6 |
| **Train/Val Gap** | < 2 dB | vs 4.6 dB in v6 |
| **Convergence** | ~50 epochs | Then plateau |
| **Best Model** | ~80-100 epochs | Before overfitting |

## Key Improvements Applied

1. **Anti-Overfitting Suite**
   - EMA model averaging
   - Stronger dropout (0.2)
   - Weight decay (0.05)
   - MixUp augmentation
   - SpecAugment masking

2. **Efficiency Optimizations**
   - Bottleneck-only attention (-40% memory)
   - LRU cache for data loading
   - Parallel dataset generation
   - Smart validation schedule

3. **Dataset Improvements**
   - 50% more training data
   - Extended audio context (6s/4s)
   - Wider SNR ranges
   - Better speaker diversity

## Troubleshooting

**If OOM Error:**
- Reduce `batch_size` to 1
- Reduce `num_workers` to 8
- Disable `persistent_workers`

**If Slow Data Loading:**
- Check cache hit rate in logs
- Increase `cache_size` in config
- Use SSD for dataset storage

**If Overfitting:**
- Ensure augmentation is enabled
- Check EMA is updating
- Consider early stopping

## Files Being Used

```
src/
â”œâ”€â”€ train_v7.py                          # Main training script
â”œâ”€â”€ models/USEF_TSE_Mamba_v7_enhanced.py # Enhanced model
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ generate_tse_dataset_v7_parallel.py
â”‚   â”œâ”€â”€ tse_dataset_v7_cached.py
â”‚   â””â”€â”€ tse_dataset_v7_augmented.py
â””â”€â”€ utils/
    â”œâ”€â”€ losses_v7.py
    â””â”€â”€ ema.py

configs/
â”œâ”€â”€ config_v7_optimized.yaml            # Training config
â””â”€â”€ dataset_config_v7_optimized.yaml    # Dataset config
```

---

**Everything is configured correctly and ready for training!** ðŸš€